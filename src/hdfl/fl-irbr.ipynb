{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a189859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import asyncio, copy, os, socket, sys, time\n",
    "from functools import partial\n",
    "from multiprocessing import Pool, Process\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../../\")))\n",
    "from libs import agg, data, fl, log, nn, poison, resnet, sim, wandb\n",
    "from cfgs.fedargs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e7e0cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'fl-poison-hdfl'\n",
    "name = 'Mnist-HDC-NA-FedAvg'\n",
    "\n",
    "#Define Custom CFGs\n",
    "#FLTrust[\"is\"] = True\n",
    "#fedargs.agg_rule = agg.Rule.FedAvg\n",
    "#mal_clients = [c for c in range(8)]\n",
    "#fang_attack[\"is\"] = True\n",
    "#lie_attack[\"is\"] = True\n",
    "#sota_attack[\"is\"] = True\n",
    "#label_flip_attack[\"is\"] = True\n",
    "#label_flip_attack[\"func\"] = poison.label_flip_next\n",
    "#set_lfa_labels(flip_labels = \"next\")\n",
    "\n",
    "# Save Logs To File (info | debug | warning | error | critical) [optional]\n",
    "log.init(\"info\",)\n",
    "#wb = wandb.init(name, project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71289620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nd\n",
    "\n",
    "'''\n",
    "r_proj = nd.random.randint(2, size=(10000,10000))\n",
    "r_proj[r_proj == 0] = -1\n",
    "r_inv_proj = nd.linalg.pinv(r_proj)\n",
    "\n",
    "print(r_proj.shape, r_inv_proj.shape)\n",
    "\n",
    "with open('proj.npy', 'wb') as f:\n",
    "    nd.save(f, r_proj)\n",
    "    \n",
    "with open('inv.npy', 'wb') as f:\n",
    "    nd.save(f, r_inv_proj)  \n",
    "'''\n",
    "\n",
    "with open('proj.npy', 'rb') as f:\n",
    "    r_proj = nd.load(f)\n",
    "\n",
    "with open('inv.npy', 'rb') as f:\n",
    "    r_inv_proj = nd.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f2d591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics.pairwise as smp\n",
    "\n",
    "def DnC(model_list, **kwargs):\n",
    "    num_buckets=1\n",
    "    bucket=100000\n",
    "        \n",
    "    all_updates = torch.tensor(model_list)\n",
    "    n, d = all_updates.shape\n",
    "\n",
    "    n_attackers = kwargs[\"beta\"]\n",
    "\n",
    "    final_indices = []\n",
    "    \n",
    "    for p in nd.arange(num_buckets):\n",
    "        idx = nd.sort(nd.random.choice(d, bucket, replace=False))\n",
    "        sampled_all_updates = all_updates[:, idx]\n",
    "        sampled_good_updates = all_updates[n_attackers:][:, idx]\n",
    "\n",
    "        centered_all_updates = sampled_all_updates - torch.mean(sampled_all_updates, 0)\n",
    "        centered_good_updates = sampled_good_updates - torch.mean(sampled_good_updates, 0)\n",
    "        \n",
    "        u, s, v = torch.svd(centered_all_updates)\n",
    "        u_g, s_g, v_g = torch.svd(centered_good_updates)\n",
    "        \n",
    "        scores = torch.mm(centered_all_updates, v[:,0][:, None]).cpu().numpy()\n",
    "        \n",
    "        final_indices.append(list(nd.argsort(scores[:,0]**2)[:(n-int(1.5*n_attackers))]))\n",
    "\n",
    "    result = set(final_indices[0]) \n",
    "    for currSet in final_indices[1:]: \n",
    "        result.intersection_update(currSet)\n",
    "    final_idx = nd.array(list(result))\n",
    "\n",
    "    model = nd.array(all_updates[final_idx]).mean(axis=0)\n",
    "    return model\n",
    "\n",
    "def FoolsGold(model_list, **kwargs):\n",
    "    len_grad = len(model_list[0])\n",
    "    n_clients = len(model_list)\n",
    "\n",
    "    cs = smp.cosine_similarity(model_list) - nd.eye(n_clients)\n",
    "    maxcs = nd.max(cs, axis=1)\n",
    "    \n",
    "    # pardoning\n",
    "    for i in range(n_clients):\n",
    "        for j in range(n_clients):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if maxcs[i] < maxcs[j]:\n",
    "                cs[i][j] = cs[i][j] * maxcs[i] / maxcs[j]\n",
    "    wv = 1 - (nd.max(cs, axis=1))\n",
    "    wv[wv > 1] = 1\n",
    "    wv[wv < 0] = 0\n",
    "\n",
    "    # Rescale so that max value is wv\n",
    "    wv = wv / nd.max(wv)\n",
    "    wv[(wv == 1)] = .99\n",
    "    \n",
    "    # Logit function\n",
    "    wv = (nd.log(wv / (1 - wv)) + 0.5)\n",
    "    wv[(nd.isinf(wv) + wv > 1)] = 1\n",
    "    wv[(wv < 0)] = 0\n",
    "\n",
    "    updated_model_list = []\n",
    "    for index, model in enumerate(model_list):\n",
    "        model = model * wv[index]\n",
    "        updated_model_list.append(model)\n",
    "                                  \n",
    "    model = nd.array(updated_model_list).mean(axis=0)\n",
    "    return model\n",
    "\n",
    "def FL_Trust(model_list, **kwargs):\n",
    "    base_model_update = get_enc_model(kwargs[\"base_model_update\"])\n",
    "    base_norm = kwargs[\"base_norm\"] if \"base_norm\" in kwargs else True\n",
    "\n",
    "    if base_norm:\n",
    "        # Base Model Norm\n",
    "        base_model_update_norm = sim.norm(base_model_update)\n",
    "\n",
    "    ts_score_list=[]\n",
    "    fl_score_list=[]\n",
    "    updated_model_list = []\n",
    "    for model in model_list:\n",
    "        ts_score = sim.cosine_similarity(base_model_update, model)\n",
    "\n",
    "        # Relu\n",
    "        if ts_score < 0:\n",
    "            ts_score = 0\n",
    "        ts_score_list.append(ts_score)\n",
    "\n",
    "        if base_norm:\n",
    "            # Model Norm    \n",
    "            norm = sim.norm(model)\n",
    "            ndiv = base_model_update_norm/norm\n",
    "            scale_norm = ts_score * ndiv\n",
    "            model = model * scale_norm\n",
    "            fl_score_list.append(scale_norm)\n",
    "        else:\n",
    "            model = model * ts_score\n",
    "\n",
    "        updated_model_list.append(model)\n",
    "    \n",
    "    log.info(\"Cosine Score {}\".format(ts_score_list))\n",
    "    log.info(\"FLTrust Score {}\".format(fl_score_list))\n",
    "        \n",
    "    model = nd.array(updated_model_list).sum(axis=0) / sum(ts_score_list)\n",
    "\n",
    "    return model\n",
    "\n",
    "def M_Krum(model_list, **kwargs):\n",
    "    beta = kwargs[\"beta\"]\n",
    "    lb = beta//2\n",
    "    ub = len(model_list) - beta//2 - 1\n",
    "\n",
    "    euclidean_dists = []\n",
    "    for index1, model1 in enumerate(model_list):\n",
    "        model_dists = []\n",
    "        for index2, model2 in enumerate(model_list):\n",
    "            if index1 != index2:\n",
    "                dist = sim.eucliden_dist(model1, model2)\n",
    "                model_dists.append(dist)\n",
    "        sq_dists = torch.sum(torch.sort(torch.tensor(model_dists)).values[lb:ub])\n",
    "        euclidean_dists.append(sq_dists)\n",
    "            \n",
    "    min_model_indices = nd.argpartition(nd.array(euclidean_dists), len(model_list) - 2*beta - 2)\n",
    "    min_model_indices = min_model_indices[:len(model_list) - 2*beta - 2]\n",
    "    log.info(\"M_Krum Candidates are {}\".format([index for index in min_model_indices]))\n",
    "    \n",
    "    model_list = [model for index, model in enumerate(model_list) if index in min_model_indices]\n",
    "    model = nd.array(model_list).mean(axis=0)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def M_Cos(model_list, **kwargs):\n",
    "    beta = kwargs[\"beta\"]\n",
    "    lb = beta//2\n",
    "    ub = len(model_list) - beta//2 - 1\n",
    "\n",
    "    cosine_dists = []\n",
    "    for index1, model1 in enumerate(model_list):\n",
    "        model_dists = []\n",
    "        for index2, model2 in enumerate(model_list):\n",
    "            if index1 != index2:\n",
    "                dist = 1 - sim.cosine_similarity(model1, model2)\n",
    "                model_dists.append(dist)\n",
    "        cos_sims = torch.sum(torch.sort(torch.tensor(model_dists)).values[lb:ub])\n",
    "        cosine_dists.append(cos_sims)\n",
    "            \n",
    "    min_model_indices = nd.argpartition(nd.array(cosine_dists), len(model_list) - 2*beta - 2)\n",
    "    min_model_indices = min_model_indices[:len(model_list) - 2*beta - 2]\n",
    "    log.info(\"M_Cos Candidates are {}\".format([index for index in min_model_indices]))\n",
    "    \n",
    "    model_list = [model for index, model in enumerate(model_list) if index in min_model_indices]\n",
    "    model = nd.array(model_list).mean(axis=0)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def T_Mean(model_list, **kwargs):\n",
    "    beta = kwargs[\"beta\"]\n",
    "    lb = beta\n",
    "    ub = len(model_list) - beta\n",
    "\n",
    "    updated_model_list = [model for model in model_list]\n",
    "    updated_model_tensors = torch.tensor(updated_model_list)\n",
    "    merged_updated_model_tensors = torch.sort(torch.stack([model for model in updated_model_tensors], 0), dim = 0)\n",
    "    merged_updated_model_arrs = torch.transpose(merged_updated_model_tensors.values, 0, 1).numpy()\n",
    "    \n",
    "    model = nd.zeros(len(model_list[0]))\n",
    "    for index, arr in enumerate(merged_updated_model_arrs):\n",
    "        model[index] = arr[lb:ub].mean(0)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8475e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enc_model(model):\n",
    "    arr, slist = sim.get_net_arr(model)\n",
    "\n",
    "    rem = nd.zeros(10000- (len(arr) % 10000))\n",
    "    if len(arr) % 10000 != 0:\n",
    "        arr = nd.concatenate((arr, rem), axis=None)\n",
    "\n",
    "    #enc_model = []\n",
    "    enc_model = nd.array([])\n",
    "    index = 0\n",
    "    while index < len(arr):\n",
    "        #enc_model.append(arr[index:index+10000] @ r_proj)\n",
    "        enc_model = nd.concatenate((enc_model, (arr[index:index+10000] @ r_proj)), axis = None)\n",
    "        index = index + 10000\n",
    "        #print(index)\n",
    "\n",
    "    return enc_model\n",
    "\n",
    "def get_enc_agg(models, **kwargs):\n",
    "    model_list = list(models.values())\n",
    "    enc_model = nd.array(model_list).mean(axis=0)\n",
    "    if fedargs.agg_rule == agg.Rule.DnC:\n",
    "        enc_model = DnC(model_list, **kwargs)\n",
    "    if fedargs.agg_rule == agg.Rule.M_Krum:\n",
    "        enc_model = M_Krum(model_list, **kwargs)\n",
    "    if fedargs.agg_rule == agg.Rule.M_Cos:\n",
    "        enc_model = M_Cos(model_list, **kwargs)\n",
    "    if fedargs.agg_rule == agg.Rule.T_Mean:\n",
    "        enc_model = T_Mean(model_list, **kwargs)\n",
    "    if fedargs.agg_rule == agg.Rule.FLTrust:\n",
    "        enc_model = FL_Trust(model_list, **kwargs)\n",
    "    if fedargs.agg_rule == agg.Rule.FoolsGold:\n",
    "        enc_model = FoolsGold(model_list, **kwargs)\n",
    "    return enc_model\n",
    "\n",
    "def get_dec_model(enc_model):\n",
    "    arr, slist = sim.get_net_arr(fedargs.model)\n",
    "    \n",
    "    rem = nd.zeros(10000- (len(arr) % 10000))\n",
    "    if len(arr) % 10000 != 0:\n",
    "        arr = nd.concatenate((arr, rem), axis=None)\n",
    "    \n",
    "    dec_model = nd.zeros(len(arr))\n",
    "    index = 0\n",
    "    while index < len(arr):\n",
    "        dec = enc_model[index: index + 10000] @ r_inv_proj\n",
    "        dec_model[index: index + 10000] = dec\n",
    "        index = index + 10000\n",
    "        #print(index)\n",
    "\n",
    "    dec_model = sim.get_arr_net(fedargs.model, dec_model, slist)\n",
    "    return dec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2bb399c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device settings\n",
    "use_cuda = fedargs.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(fedargs.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "76542fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare clients\n",
    "host = socket.gethostname()\n",
    "clients = [host + \"(\" + str(client + 1) + \")\" for client in range(fedargs.num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "402306c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Initialize Global and Client models\n",
    "global_model = copy.deepcopy(fedargs.model)\n",
    "# Load Data to clients\n",
    "train_data, test_data = data.load_dataset(fedargs.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca573ed",
   "metadata": {},
   "source": [
    "<h2>FLTrust</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bbe42e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLTrust[\"is\"]:\n",
    "    train_data, FLTrust[\"data\"] = data.random_split(train_data, FLTrust[\"ratio\"])\n",
    "    FLTrust[\"loader\"] = torch.utils.data.DataLoader(FLTrust[\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "    if FLTrust[\"proxy\"][\"is\"]:\n",
    "        FLTrust[\"data\"], FLTrust[\"proxy\"][\"data\"] = data.random_split(FLTrust[\"data\"], FLTrust[\"proxy\"][\"ratio\"])\n",
    "        FLTrust[\"loader\"] = torch.utils.data.DataLoader(FLTrust[\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)\n",
    "        FLTrust[\"proxy\"][\"loader\"] = torch.utils.data.DataLoader(FLTrust[\"proxy\"][\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8025440b",
   "metadata": {},
   "source": [
    "<h2>Prepare a backdoored loader for test</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "769acb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backdoor_attack[\"is\"]:\n",
    "    train_data, backdoor_attack[\"data\"] = data.random_split(train_data, backdoor_attack[\"ratio\"])\n",
    "    backdoor_attack[\"data\"] = poison.insert_trojan(backdoor_attack[\"data\"],\n",
    "                                                   backdoor_attack[\"target_label\"],\n",
    "                                                   backdoor_attack[\"trojan_func\"], 1)\n",
    "    backdoor_attack[\"loader\"] = torch.utils.data.DataLoader(backdoor_attack[\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f568d4",
   "metadata": {},
   "source": [
    "<h2>Load client's data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "80508740",
   "metadata": {},
   "outputs": [],
   "source": [
    "iidargs = {\"non_iid\": False, \"rate_unbalance\": 0.25}\n",
    "clients_data = data.split_data(train_data, clients, **iidargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aacd7b",
   "metadata": {},
   "source": [
    "<h2>HDC DP Attack</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c15880d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def hdc_train(hdc_data, device, hdc_args):\n",
    "    hdc_data_loader = torch.utils.data.DataLoader(hdc_data, batch_size=len(hdc_data), shuffle=True)\n",
    "    hdc_model = hdc.HDC(hdc_args[\"one_d_len\"], hdc_args[\"hdc_proj_len\"], len(hdc_args[\"labels\"]), device)\n",
    "    train_acc = hdc_model.train(hdc_data_loader, device)\n",
    "    return hdc_model\n",
    "\n",
    "if hdc_dp_attack[\"is\"]:\n",
    "    hdc_tasks = [hdc_train(clients_data[clients[client]], device,\n",
    "                            hdc_dp_attack[\"args\"]) for client in mal_clients]\n",
    "    try:\n",
    "        hdc_models = fedargs.loop.run_until_complete(asyncio.gather(*hdc_tasks))\n",
    "    except KeyboardInterrupt as e:\n",
    "        log.error(\"Caught keyboard interrupt. Canceling hdc_dps...\")\n",
    "        hdc_tasks.cancel()\n",
    "        fedargs.loop.run_forever()\n",
    "        hdc_tasks.exception()\n",
    "\n",
    "    hdc_clients_data = {client: (clients_data[clients[client]], hdc_models[index])\n",
    "                        for index, client in enumerate(mal_clients)}\n",
    "\n",
    "    mal_clients_data = hdc_dp_attack[\"func\"](hdc_clients_data,\n",
    "                                             hdc_dp_attack[\"args\"],\n",
    "                                             label_flip_attack[\"labels\"],\n",
    "                                             hdc_dp_attack[\"percent\"])\n",
    "\n",
    "    for client, mal_data in enumerate(mal_clients_data):\n",
    "        clients_data[clients[client]] = mal_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0670c19d",
   "metadata": {},
   "source": [
    "<h2>Label Flip Attack</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43985c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if label_flip_attack[\"is\"]:\n",
    "    for client in mal_clients:\n",
    "        clients_data[clients[client]] = label_flip_attack[\"func\"](clients_data[clients[client]],\n",
    "                                                                  label_flip_attack[\"labels\"],\n",
    "                                                                  label_flip_attack[\"percent\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c01394f",
   "metadata": {},
   "source": [
    "<h2>Backdoor Attack</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "11198f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backdoor_attack[\"is\"]:\n",
    "    for client in mal_clients:\n",
    "        clients_data[clients[client]] = poison.insert_trojan(clients_data[clients[client]],\n",
    "                                                             backdoor_attack[\"target_label\"],\n",
    "                                                             backdoor_attack[\"trojan_func\"], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f21c1481",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_train_loaders, _ = data.load_client_data(clients_data, fedargs.client_batch_size, None, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=fedargs.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "client_details = {\n",
    "        client: {\"train_loader\": client_train_loaders[client],\n",
    "                 \"model\": copy.deepcopy(global_model),\n",
    "                 \"model_update\": None}\n",
    "        for client in clients\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "af4f472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def process(client, epoch, model, train_loader, fedargs, device):\n",
    "    # Train\n",
    "    model_update, model, loss = fedargs.train_func(model, train_loader, \n",
    "                                                   fedargs.learning_rate,\n",
    "                                                   fedargs.weight_decay,\n",
    "                                                   fedargs.local_rounds, device)\n",
    "\n",
    "    log.jsondebug(loss, \"Epoch {} of {} : Federated Training loss, Client {}\".format(epoch, fedargs.epochs, client))\n",
    "    log.modeldebug(model_update, \"Epoch {} of {} : Client {} Update\".format(epoch, fedargs.epochs, client))\n",
    "    \n",
    "    enc_model_update = get_enc_model(model_update)\n",
    "    return model_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae7b9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]2023-01-10 11:58:59,843 - <ipython-input-73-c90d66ef5169>::<module>(l:6) : Federated Training Epoch 0 of 21 [MainProcess : MainThread (INFO)]\n"
     ]
    }
   ],
   "source": [
    "##### import time\n",
    "start_time = time.time()\n",
    "    \n",
    "# Federated Training\n",
    "for epoch in tqdm(range(fedargs.epochs)):\n",
    "    log.info(\"Federated Training Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "\n",
    "    # Global Model Update\n",
    "    if epoch > 0:\n",
    "        # For Tmean and FLTrust, not impacts others as of now\n",
    "        avgargs = {\"beta\": len(mal_clients), \n",
    "                   \"base_model_update\": global_model_update if FLTrust[\"is\"] else None,\n",
    "                   \"base_norm\": True}\n",
    "        \n",
    "        # Average\n",
    "        #global_model = fl.federated_avg(client_model_updates, global_model, fedargs.agg_rule, **avgargs)\n",
    "        model_update = get_dec_model(get_enc_agg(client_model_updates, **avgargs))\n",
    "        global_model = agg.sub_model(global_model, model_update)\n",
    "        log.modeldebug(global_model, \"Epoch {}: Server Update\".format(epoch))\n",
    "        \n",
    "        # Test, Plot and Log\n",
    "        global_test_output = fedargs.eval_func(global_model, test_loader, device, label_flip_attack[\"labels\"])\n",
    "        wb.log({\"epoch\": epoch, \"time\": time.time(), \"acc\": global_test_output[\"accuracy\"], \"loss\": global_test_output[\"test_loss\"]})\n",
    "        log.jsoninfo(global_test_output, \"Global Test Outut after Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "        \n",
    "        # Evaluate LFA\n",
    "        if \"attack\" in global_test_output:\n",
    "            if \"attack_success_rate\" in global_test_output[\"attack\"]:\n",
    "                wb.log({\"attack_success_rate\": global_test_output[\"attack\"][\"attack_success_rate\"]})\n",
    "            if \"misclassification_rate\" in global_test_output[\"attack\"]:\n",
    "                wb.log({\"misclassification_rate\": global_test_output[\"attack\"][\"misclassification_rate\"]})\n",
    "\n",
    "        # Evaluate Backdoor\n",
    "        if backdoor_attack[\"is\"]:\n",
    "            backdoor_test_output = fl.backdoor_test(global_model, backdoor_attack[\"loader\"], device, backdoor_attack[\"target_label\"])\n",
    "            wb.log({\"backdoor_success_rate\": backdoor_test_output[\"accuracy\"]})\n",
    "            log.jsoninfo(backdoor_test_output, \"Backdoor Test Outut after Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "\n",
    "        # Update client models\n",
    "        for client in clients:\n",
    "            client_details[client]['model'] = copy.deepcopy(global_model)\n",
    "\n",
    "    # Clients\n",
    "    tasks = [process(client, epoch, client_details[client]['model'],\n",
    "                     client_details[client]['train_loader'],\n",
    "                     fedargs, device) for client in clients]\n",
    "    try:\n",
    "        updates = fedargs.loop.run_until_complete(asyncio.gather(*tasks))\n",
    "    except KeyboardInterrupt as e:\n",
    "        log.error(\"Caught keyboard interrupt. Canceling tasks...\")\n",
    "        tasks.cancel()\n",
    "        fedargs.loop.run_forever()\n",
    "        tasks.exception()\n",
    "\n",
    "    for client, update in zip(clients, updates):\n",
    "        client_details[client]['model_update'] = update\n",
    "    client_model_updates = {client: details[\"model_update\"] for client, details in client_details.items()}\n",
    "    \n",
    "    # Fang attack\n",
    "    if fang_attack[\"is\"]:\n",
    "        client_model_updates = fang_attack[\"func\"](client_model_updates, len(mal_clients), fang_attack[\"kn\"])\n",
    "        \n",
    "    # LIE attack\n",
    "    if lie_attack[\"is\"]:\n",
    "        client_model_updates = lie_attack[\"func\"](client_model_updates, len(mal_clients), lie_attack[\"kn\"])\n",
    "   \n",
    "    # SOTA attack\n",
    "    if sota_attack[\"is\"]:\n",
    "        client_model_updates = sota_attack[\"func\"](client_model_updates, len(mal_clients), \n",
    "                                                   sota_attack[\"kn\"], sota_attack[\"dev_type\"])\n",
    "    \n",
    "    # FLtrust or FLTC based aggregation rules or attacks\n",
    "    if FLTrust[\"is\"]:\n",
    "        global_model_update, _, _ = fedargs.train_func(global_model, FLTrust[\"loader\"],\n",
    "                                                       fedargs.learning_rate,\n",
    "                                                       fedargs.weight_decay,\n",
    "                                                       fedargs.local_rounds, device)\n",
    "\n",
    "        # For Attacks related to FLTrust\n",
    "        base_model_update = global_model_update\n",
    "        if FLTrust[\"proxy\"][\"is\"]:\n",
    "            base_model_update, _, _ = fedargs.train_func(global_model, FLTrust[\"proxy\"][\"loader\"],\n",
    "                                                         fedargs.learning_rate,\n",
    "                                                         fedargs.weight_decay,\n",
    "                                                         fedargs.local_rounds, device)\n",
    "        \n",
    "        # Layer replacement attack\n",
    "        if layer_replacement_attack[\"is\"]:\n",
    "            for client in mal_clients:\n",
    "                client_details[clients[client]]['model_update'] = layer_replacement_attack[\"func\"](base_model_update,\n",
    "                                                                                                   client_details[clients[client]]['model_update'],\n",
    "                                                                                                   layer_replacement_attack[\"layers\"])\n",
    "\n",
    "        # For cosine attack, Malicious Clients\n",
    "        if cosine_attack[\"is\"]:\n",
    "            p_models, params_changed = cosine_attack[\"func\"](base_model_update, cosine_attack[\"args\"], epoch,\n",
    "                                                             client_model_updates, len(mal_clients), cosine_attack[\"kn\"])\n",
    "            \n",
    "            for client, p_model in enumerate(p_models):\n",
    "                client_details[clients[client]]['model_update'] = p_model \n",
    "\n",
    "            #plot params changed for only one client\n",
    "            fedargs.tb.add_scalar(\"Params Changed for Cosine Attack/\", params_changed, epoch)\n",
    "\n",
    "        # For sybil attack, Malicious Clients\n",
    "        if sybil_attack[\"is\"]:\n",
    "            for client in mal_clients:\n",
    "                client_details[clients[client]]['model_update'] = base_model_update\n",
    "                \n",
    "        # again pair, as changed during attack\n",
    "        client_model_updates = {client: details[\"model_update\"] for client, details in client_details.items()}\n",
    "    \n",
    "    client_model_updates = {client: get_enc_model(details[\"model_update\"]) for client, details in client_details.items()}\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b2d6a9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<h1> End </h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:syft]",
   "language": "python",
   "name": "conda-env-syft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
